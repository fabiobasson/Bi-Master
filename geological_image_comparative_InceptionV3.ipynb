{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "geological-image-comparative_InceptionV3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMcVR1kdjpFT6gaiGSzsa9x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabiobasson/Bi-Master/blob/main/geological_image_comparative_InceptionV3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VrsKA1TBu-C"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "from os import getcwd\n",
        "import zipfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "import glob\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import plotly.express as px\n",
        "import cv2 as cv\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKzDC66jCXmI"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_hV2lrVCem5"
      },
      "source": [
        "#!kaggle datasets download fabiobasson/geologicalsimilarity\n",
        "#! unzip -qq  geologicalsimilarity\n",
        "!kaggle datasets download tanyadayanand/geological-image-similarity\n",
        "! unzip -qq geological-image-similarity "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kskH9ATeCeqS"
      },
      "source": [
        "andesite_dir = glob.glob('geological_similarity/andesite/*.jpg');gneiss_dir = glob.glob('geological_similarity/gneiss/*.jpg')\n",
        "marble_dir= glob.glob('geological_similarity/marble/*.jpg');quartzite_dir = glob.glob('geological_similarity/quartzite/*.jpg')\n",
        "rhyolite_dir = glob.glob('geological_similarity/rhyolite/*.jpg');\n",
        "schist_dir = glob.glob('geological_similarity/schist/*.jpg')\n",
        "print(len(andesite_dir));print(len(gneiss_dir)); print(len(marble_dir)); print(len(quartzite_dir));  print(len(quartzite_dir)); print(len(schist_dir))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTXg3CZsCYBW"
      },
      "source": [
        "label = ['andesite','gneiss','marbler','quartzite','rhyolite','schist']\n",
        "\n",
        "andesite_df=[];gneiss_df=[];marble_df=[];quartzite_df=[];rhyolite_df=[];schist_df=[]\n",
        "\n",
        "for i in andesite_dir:\n",
        "    andesite_df.append([i,label[0]])\n",
        "for j in gneiss_dir:\n",
        "   gneiss_df.append([j,label[1]])\n",
        "for l in marble_dir:\n",
        "    marble_df.append([l,label[2]])\n",
        "for m in quartzite_dir:\n",
        "    quartzite_df.append([m,label[3]])\n",
        "for n in rhyolite_dir:\n",
        "    rhyolite_df.append([n,label[4]])\n",
        "for o in schist_dir:\n",
        "    schist_df.append([o,label[5]])\n",
        "   \n",
        "df = andesite_df + gneiss_df + marble_df  + quartzite_df + rhyolite_df + schist_df\n",
        "random.shuffle(df)\n",
        "len(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EUPTtAVCobE"
      },
      "source": [
        "data_df = pd.DataFrame(df,columns=['path','label'])\n",
        "data_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKiwN2x2Cofq"
      },
      "source": [
        "X = data_df.drop(columns='label')\n",
        "y = data_df.label\n",
        "\n",
        "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k240Dl3uCwtR"
      },
      "source": [
        "IMG_SHAPE = 28\n",
        "IMG_SHAPE_V3 = 75\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip(images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_z4kBmVjCwy0"
      },
      "source": [
        "# Dados de Treino e Validação\n",
        "\n",
        "datagen_train = ImageDataGenerator(rescale=1./255,\n",
        "                            #featurewise_center =False ,\n",
        "                            # samplewise_center =False ,\n",
        "                            # featurewise_std_normalization =False ,\n",
        "                            # samplewise_std_normalization =False ,\n",
        "                            # zca_whitening =False ,\n",
        "                            # zca_epsilon =1e -6 ,\n",
        "                            # channel_shift_range =0. ,\n",
        "                            # fill_mode = ’ nearest ’ ,\n",
        "                            # cval =0. ,\n",
        "                            rotation_range = 40,\n",
        "                            width_shift_range = 0.2,\n",
        "                            height_shift_range = 0.2,\n",
        "                            #shear_range = 0.2,\n",
        "                            #zoom_range = 0.2,\n",
        "                            horizontal_flip = True,\n",
        "                            vertical_flip = True,\n",
        "                            validation_split=0.2)\n",
        "\n",
        "train_generator = datagen_train.flow_from_dataframe(data_df,\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               x_col='path',\n",
        "                                               y_col= 'label',\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                               #target_size=(IMG_SHAPE_V3,IMG_SHAPE_V3),\n",
        "                                               class_mode='categorical',\n",
        "                                               subset='training')\n",
        "\n",
        "\n",
        "datagen_val = ImageDataGenerator (rescale=1./255, \n",
        "                                 validation_split=0.2)\n",
        "\n",
        "\n",
        "validation_generator = datagen_val.flow_from_dataframe(data_df,\n",
        "                                                   batch_size=BATCH_SIZE,\n",
        "                                                   x_col='path',\n",
        "                                                   y_col='label',\n",
        "                                                   shuffle=True,\n",
        "                                                   target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                   #target_size=(IMG_SHAPE_V3,IMG_SHAPE_V3),\n",
        "                                                   class_mode='categorical',\n",
        "                                                   subset='validation')    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cfpoa0HCw4Q"
      },
      "source": [
        "# Dados de Teste\n",
        "\n",
        "datagen_test = ImageDataGenerator (rescale=1./255, \n",
        "                                 validation_split=0.2)\n",
        "\n",
        "\n",
        "test_generator = datagen_test.flow_from_dataframe(data_df,\n",
        "                                                   batch_size=BATCH_SIZE,\n",
        "                                                   x_col='path',\n",
        "                                                   y_col='label',\n",
        "                                                   shuffle=False,\n",
        "                                                   target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                  #target_size=(IMG_SHAPE_V3,IMG_SHAPE_V3),\n",
        "                                                   class_mode='categorical')\n",
        "                                                   #subset='validation') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtGOoLNDCw7F"
      },
      "source": [
        "augmented_images = [train_generator[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqZeS2VHCw_c"
      },
      "source": [
        "X_train, y_train = next(train_generator)\n",
        "X_val, y_val = next(validation_generator)\n",
        "X_test, y_test = next(test_generator)\n",
        "\n",
        "X_val.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oLQl_nEDKnj"
      },
      "source": [
        "import tensorflow.keras.applications as app\n",
        "print(dir(app))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3H8ShUGCYEx"
      },
      "source": [
        "#inception_v3 = InceptionV3(input_shape=(75, 75, 3),\n",
        "                           #weights='imagenet',\n",
        "                           #include_top=False)\n",
        "#inception_v3.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIFh0kzsBxTO"
      },
      "source": [
        "classifier_v3 = InceptionV3(include_top=False, input_shape=(75, 75, 3)) \n",
        "\n",
        "# marcar camadas como não treináveis\n",
        "for layer in classifier.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = tf.keras.layers.Flatten()(classifier_v3.layers[-1].output)\n",
        "x = Dense(512, activation='relu', kernel_initializer='he_uniform')(x)\n",
        "output = Dense(6, activation='softmax')(x)\n",
        "\n",
        "#x = layers.Flatten()(inception_v3.output)\n",
        "#x = layers.BatchNormalization()(x)\n",
        "#x = layers.Dense(512,activation='relu')(x)\n",
        "#x = layers.Dropout(0.2)(x)                  \n",
        "#x = layers.Dense(6,activation='softmax')(x)           \n",
        "\n",
        "# definir o modelo\n",
        "modelinception_v3 = Model(inputs=classifier_v3.input, outputs=output) \n",
        "\n",
        "modelinception_v3.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUdELYi8B3D3"
      },
      "source": [
        "modelinception_v3.compile(optimizer = Adam(learning_rate=0.0001), \n",
        "               loss = 'categorical_crossentropy', \n",
        "               metrics =['accuracy'])\n",
        "\n",
        "callbacksinception_v3 = [\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.5,\n",
        "                                         patience=4,\n",
        "                                         verbose=0),\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"accuracy\",\n",
        "        patience=12,\n",
        "        restore_best_weights=True,\n",
        "    ),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath='inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_accuracy\",\n",
        "    ),\n",
        "\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51lc-YWGB3wK"
      },
      "source": [
        "epochs=100\n",
        "\n",
        "historyv3 = modelinception_v3(train_generator,\n",
        "                               steps_per_epoch = 23999/256,\n",
        "                               epochs=epochs,\n",
        "                               callbacks=callbacksinception_v3,\n",
        "                               validation_data=validation_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K7oYB_fB6U3"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovdjD44HB6ZH"
      },
      "source": [
        "modelinception_v3 = tf.keras.models.load_model(\"inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
        "\n",
        "test_lossinception_v3, test_accinception_v3= modelinception_v3.evaluate(X_test,y_test)\n",
        "print(\"validation_accuracy: \" + str(test_accvinception_v3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0zKWe2vB_C7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}